# TECtools - TECprobe tools

[**cotrans_preprocessor**](#processing-tecprobe-data-using-cotrans_preprocessor) - Performs sequencing read preprocessing to prepare data for analysis by ShapeMapper2 (https://github.com/Weeks-UNC/shapemapper2)

[**mkmtrx**](#assembling-tecprobe-vl-data-using-mkmtrx) - Assembles data into matrix and other useful formats, reports alignment rates, and can be used to generate rdat files

[**mtrx2cols**](#extract-reactivity-trajectories-using-mtrx2cols) - Extracts reactivity trajectories for specific nucleotides from a reactivity matrix


## Processing TECprobe data using cotrans_preprocessor

`cotrans_preprocessor` performs sequencing read preprocessing to prepare data for analysis by `ShapeMapper2`. The expected run time is variable depending on the size of the  data set. A TECprobe-VL data set with a typical sequencing depth (60-100M paired end reads) will typically take 30-60 minutes to process.

**`cotrans_preprocessor` requires that `fastp` (https://github.com/OpenGene/fastp) is installed**

**analysis of TECprobe using `cotrans_preprocessor` requires that `ShapeMapper2` (https://github.com/Weeks-UNC/shapemapper2) is installed** 

### Set cotrans_preprocessor run mode (required for all run modes)

```
-m/--mode <run_mode_specifier>

run_mode_specifiers:

  MAKE_FASTA          Generate FASTA file to be used for target generation
  
  MAKE_3pEND_TARGETS  Generate 3' end targets to be used for demultiplexing FASTQ files by 
                      transript length, and intermediate transcript targets to be used for 
                      sequencing read alignment. 3' end targets contain all native and 1 nt
                      substitution, insertion, and deletion variants of the last 14 nt 
                      (or more, if specified) of every possible intermediate transcript.
  
  PROCESS_MULTI       Perform preprocessing for TECprobe-VL experiments
  
  PROCESS_SINGLE      Perform preprocessing for TECprobe-SL experiments
  
  MAKE_RUN_SCRIPT     Generate shell script for running ShapeMapper2
```


### MAKE_FASTA mode inputs and options

Required:

```
-n/--seq-name <name_of_sequence>  Target name.

-s/--sequence <sequence>          Target sequence.
```


### MAKE_3pEnd_TARGETS mode inputs and options

Required:
```
-A/--fasta  <fasta_file>  Target sequence in FASTA format. Can be generated by running
                          cotrans_preprocessor in MAKE_FASTA mode.
```

Optional:
```
-E/--end-length <n>     Length of 3' end targets. Default=14, 3' end target length should ideally
                        be 14-16 nt, because the E. coli RNA polymerase footprint on RNA is 14-15 nt.
                        
-S/--min-length <n>     Minimum intermediate transcript target length. Default=20.

-T/--test-data          Generate test data to be used for validating transcript 3' end mapping.
                        By default, generates 1000 test_data reads per intermediate transcript
                        using native sequence with randomized channel barcodes.
                        
-U/--multiplier <n>     Multiply the number of test_data reads generated by <n>.

-R/--end-randomization  Make random 1 nt substitutions, insertions, and deletions in the last
                        <end_length> nts of test_data reads. End-randomization should be used
                        to validate correct 3' end mapping. Complete coverage of all 1 nt
                        variations typically requires that --multiplier be set to at least 30.
```


### PROCESS_MULTI and PROCESS_SINGLE mode inputs and options

Required for PROCESS_MULTI and PROCESS_SINGLE modes:

```
-i/--read1 <read1_fastq>      Read 1 FASTQ file input.

-I/--read2 <read2_fastq>      Read 2 FASTQ file input.
```

Required for PROCESS_MULTI mode only:

```
-e/--3pEnd <3'_end_targets>   3' end targets file input.
```

Required for PROCESS_SINGLE mode only:

```
-a/--fasta-ref <fasta_file>   FASTA file containing single target.
```

Optional:

```
-p/--fastp-path <fastp_path>  Path to fastp executable

-t/--testdata                 Enable test data analysis. This option should only be used
                              when analyzing test_data sequencing reads that were 
                              generated in MAKE_3pEND_TARGETS mode using the -T option.
```


### MAKE_RUN_SCRIPT mode input

Required:
```
-c/--config <config_file>     Run script configuration file input.
```

### Basic usage of cotrans_preprocessor

1.  Generate a target sequence FASTA file by running `cotrans_preprocessor` in `MAKE_FASTA` mode:
    
    `cotrans_preprocessor -m MAKE_FASTA -n <target_RNA_name> -s <target_RNA_sequence>`
    
    This will generate a FASTA file named `<target_RNA_name>.fa` with the sequence `<target_RNA_sequence>`.
    

2.  If analyzing TECprobe-VL data, generate 3' end and intermediate transcript targets by
    running `cotrans_preprocessor` in `MAKE_3pEND_TARGET` mode:
    
    without test_data:
    
    `cotrans_preprocessor -m MAKE_3pEND_TARGETS -A <target_RNA_fasta_file>`
    
    with native 3' end test_data generation:
    
    `cotrans_preprocessor -m MAKE_3pEND_TARGETS -A <target_RNA_fasta_file> -T`
    
    with randomized 3' end test_data generation:
    
    `cotrans_preprocessor -m MAKE_3pEND_TARGETS -A <target_RNA_fasta_file> -T -R -U 30`
    
    This will generate a directory `<target_RNA_name>_targets` that contains:
      * a 3' end targets file `<target_RNA_name>_ends_<n>ntLong.txt`, where <n> is the
        length of the 3' end targets
      * a sub-directory called `intermediate_transcripts` that contains a FASTA file for
        every intermediate transcript sequence
      * a sub-directory called `metrics` that contains target generation QC metrics files
      * if test_data generation was enabled, a sub-directory called test_data that contains
        test_data fastq files
    
3.  Process sequencing reads:

    If analyzing TECprobe-VL data, run `cotrans_preprocessor` in `PROCESS_MULTI` mode:
  
    `cotrans_preprocessor -m PROCESS_MULTI -i <read1_fastq_file> -I <read2_fastq_file> -e <3p_ends_target file>`
  
    If analyzing TECprobe-SL data, run `cotrans_preprocessor` in `PROCESS_SINGLE` mode:
  
    `cotrans_preprocessor -m PROCESS_SINGLE -i <read1_fastq_file> -I <read2_fastq_file> -a <target_RNA_FASTA_file>`
    
    This will generate
      * `fastp` output files `fastp.html` and `fastp.json`
      * `processing.txt`, which contains sequencing read processing metrics
      * `length_distribution.txt` which contains the number of reads that mapped to each transcript length
      * a directory called `split` that contains 
        * fastq files split by untreated/modified channel and transcript length (PROCESS_MULTI only)
        * `smooth_transition.sh` which can be used to concatenate fastq files for neighboring transcripts when performing neighboring transcript smoothing
      * `config.txt` which is used to configure ShapeMapper2 run script generation 
    
4. If performing neighboring transcript smoothing, run the command:

  `sh ./split/smooth_transition.sh`
  
  This will generate the directory `split_smooth` that contains fastq files in which sequencing reads for neighboring transcripts have been concatenated.
  
5. Make a directory for running ShapeMapper2, copy config.txt to that directory, and change to that directory
    
6. Generate a ShapeMapper2 run script:

   After providing all required information in the `config.txt` file, run `cotrans_preprocessor` in `MAKE_RUN_SCRIPT` mode:
   
   `cotrans_preprocessor -m MAKE_RUNSCRIPT -c config.txt`
   
   This will generate 
   * parsed_config.txt, which reports the settings that were parsed from config.txt
   * a shell script containing commands to run ShapeMapper2 analysis for every intermediate transcript
     
7. Run the shell script that was generated in Step 6 to start ShapeMapper2 processing.
  
## Normalizing TECprobe-VL data using process_TECprobeVL_profiles  

`process_TECprobeVL_profiles` performs whole-dataset normalization for TECprobe-VL data (which is normalized on a per-transcript length basis during analysis) and assembles ShapeMapper2 (https://github.com/Weeks-UNC/shapemapper2) output file data into a single csv file that is compatible with TECprobe visualization tools. Normalization is performed exactly as in ShapeMapper2:

```
"Over the set of all RNAs and nucleotide positions without masked (lowercase) sequence, high background, or
low read depth, reactivities are normalized by dividing by the mean reactivity of the top 10% of reactivities
after reactivities above a threshold are excluded (see section 3.2.1 in Low and Weeks, 2010). That threshold
is selected from the largest value out of [1.5 Ã— interquartile range, 90th percentile (if total seq length > 100)
or 95th percentile (if total seq length < 100)]." - ShapeMapper2 README
```

If more than one input directory is provided, `process_TECprobeVL_profiles` will merge the data into a single dataset. Therefore, only replicate data sets should be provided together. `process_TECprobeVL_profiles` checks the attributes of input data names and the data itself to confirm that input datasets are compatible.

### process_TECprobeVL_profiles inputs and options
  
Required:
```
-i/--input <data_directory>     Input TECprobe-VL data directory. This should be the directory in which the
                                ShapeMapper2 run script was executed. If more than one compatible input directory
                                is provided, the data will be merged.
```
 
Optional:
```
-o/--out_dir_name <input>       Output directory name. Default = 'dataset_norm_out'
-n/--sample-name <input>        Sample name. If no sample name is provided, a sample name will be automatically
                                generated from the input data names.
-e/--min-depth <n>              Minimum read depth for high-quality nucleotides. Default = 5000.
-b/--max-background <n>         Maximum background mutation rate for high-quality nucleotides. Default = 0.05.
```

### Basic usage of process_TECprobeVL_profiles

To process a single TECprobe-VL dataset, run the command: 
`process_TECprobeVL_profiles -i <data_directory>`

To merge three TECprobe-VL datasets, run the command: 
`process_TECprobeVL_profiles -i <data_directory> -i <data_directory> -i <data_directory>`

## Assembling TECprobe-VL data using mkmtrx
 
`mkmtrx` assembles data into matrix and other useful formats, reports alignment rates, and can be used to generate rdat files.
  
### mkmtrx inputs and options
  
Required:
```
-m/--mode <run_mode_specifier>  Set run mode. Valid run_mode_specifier values are `MULTI` for
                                TECprobe-VL data and `SINGLE` for TECprobe-SL data
-i/--input <data_directory>     The directory in which the ShapeMapper2 run script was executed
-c/--reactivity-col <input>     Set reactivity value to output. Valid inputs are `REACTIVITY_PROFILE`
                                for unfilitered raw reactivity, `HQ_PROFILE` for high quality nucleotide
                                raw reactivity, and `NORM_PROFILE` for normalized reactivity.
```
 
Optional:
```
-w/--include-up-to <n>          Whitelist transcripts up to length <n> for inclusion in columnized reactivities 
-x/--exclude-term <n>           Exclude transcripts after length <n> from columnized reactivities
```

### Basic usage of mkmtrx

Run the command: 
`mkmtrx -m <run_mode_specifier> -i <data_directory>`
  
This will generate the following files in <data_directory>
  * `<data_directory>_reactivity.csv` which contains a matrix of raw reactivity values
  * `<data_directory>_untreated.csv`  which contains a matrix of untreated effective read depth values
  * `<data_directory>_modified.csv`   which contains a matrix of modified effective read depth values
  * `<data_directory>_alignment_totals.txt` which contains the number of reads that passed processing
    by 'cotrans_preprocessor` and the number of reads that aligned
  * `<data_directory>_alignment_rates.txt` which contains alignment rates for each transcript length
  * `<data_directory>_columns.txt` which contains a column of all reactivity values transcripts that
    were enriched by biotin-streptavidin roadblocks (which can be modified using the `--include-up-to` and
    `--exclude-term` options. The columnized reactivities are useful for plotting replicate correlation.
  * `<data_directory>_linebars.txt` which contains reactivites formatted for making overlapping bar plots

  
## Extract reactivity trajectories using mtrx2cols
    
`mtrx2cols` extracts reactivity trajectories for specific nucleotides from one or more reactivity matrices.
  
### mtrx2cols inputs and options
  
Required:
```
-m/--matrix <matrix_csv>  Reactivity matrix in csv format.
-f/--filter <filter_file> Filter file that specifies what nucleotides should be extractd and what 
                          transcript length windows should be output for each nucleotide. 
```
  
The format for the filter file is:

```
line1: 'nts=' followed by a list of comma-separated values specifying which nucleotide trajectores to extract.
  
line2: min=<n>,max=<m>, where <n> and <m> are the start and end of a transcript length window. Multiple transcript
       length window lines can be included.
```
  

For example, the filter
  
```
nts=68,69,70
min=20,max=137
min=169,max=172
  
```

will generate a file containing reactivity trajectories for nucleotides 67, 69, and 70 for windows from transcripts
20 to 137 and 169 to 172.
  
  
Optional:
```
-a/--alias <alias_file>   File containing aliases for input data. The --alias
                          option must be supplied **after** all reactivity matrix
                          csv files
-o/--output <output_name> Output file name
```
  
The format for the alias file is:
  
`<input_matrix_name><tab><alias>`
  
Aliases for multiple reactivity matrices can be supplied in the same alias file if more than one reactivity matrix csv is being processed.
  
### Basic usage of mtrx2cols
  
`mtrx2cols -m <matrix_csv1> -m <matrix_csv2> -a <aliases> -f <filter> -o <output_file_name>`
  
will generate a file `<output_file_name>.txt` that contains reactivity trajectories for the nucleotide specified by `<filter>`, with column names that use the aliases supplied by `<aliases>`.
